---
phase: 03-call-extraction-price-data
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - api/Gemfile
  - api/app/services/calls/extraction_service.rb
  - api/app/services/calls/prompt_builder.rb
  - api/app/services/calls/call_parser.rb
  - api/app/jobs/extract_calls_job.rb
  - api/app/jobs/extract_all_pending_calls_job.rb
  - api/config/recurring.yml
autonomous: true
user_setup:
  - service: openai
    why: "LLM-based call extraction from content"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Platform -> API keys (https://platform.openai.com/api-keys)"

must_haves:
  truths:
    - "System extracts market calls from YouTube transcripts using GPT-4o-mini"
    - "System extracts market calls from tweets using GPT-4o-mini"
    - "Extracted calls have direction (bullish/bearish), confidence score, quote snippet, and reasoning"
    - "Only calls with confidence >= 0.7 are stored; lower confidence marked as low_confidence"
    - "Content records are marked with extraction_status after processing"
    - "Extraction runs automatically on a recurring schedule"
  artifacts:
    - path: "api/app/services/calls/extraction_service.rb"
      provides: "Orchestrates LLM extraction for a single content item"
      contains: "OpenAI::Client"
    - path: "api/app/services/calls/prompt_builder.rb"
      provides: "Builds system and user prompts for different content types"
      contains: "SYSTEM_PROMPT"
    - path: "api/app/services/calls/call_parser.rb"
      provides: "Parses LLM JSON response into Call records"
      contains: "Asset.find_by"
    - path: "api/app/jobs/extract_all_pending_calls_job.rb"
      provides: "Batch dispatcher for unprocessed content"
      contains: "extraction_status"
  key_links:
    - from: "api/app/services/calls/extraction_service.rb"
      to: "api/app/services/calls/prompt_builder.rb"
      via: "PromptBuilder call in extract method"
      pattern: "PromptBuilder"
    - from: "api/app/services/calls/extraction_service.rb"
      to: "api/app/services/calls/call_parser.rb"
      via: "CallParser call to create records"
      pattern: "CallParser"
    - from: "api/app/jobs/extract_calls_job.rb"
      to: "api/app/services/calls/extraction_service.rb"
      via: "Service invocation in perform"
      pattern: "ExtractionService"
    - from: "api/app/jobs/extract_all_pending_calls_job.rb"
      to: "api/app/jobs/extract_calls_job.rb"
      via: "Spawns per-content jobs"
      pattern: "ExtractCallsJob.perform_later"
---

<objective>
Build the LLM-based call extraction pipeline: services that send content to GPT-4o-mini, parse structured JSON responses into Call records, and background jobs that run extraction on a schedule.

Purpose: This is the core intelligence layer -- turning raw content (transcripts, tweets) into structured market calls (bullish/bearish on specific assets).
Output: Call extraction services, background jobs, recurring schedule for automatic processing.
</objective>

<execution_context>
@/Users/superuser/.claude/get-shit-done/workflows/execute-plan.md
@/Users/superuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-call-extraction-price-data/03-RESEARCH.md
@api/app/models/call.rb
@api/app/models/asset.rb
@api/app/models/content.rb
@api/app/models/influencer.rb
@api/app/jobs/sync_youtube_channels_job.rb
@api/config/recurring.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add ruby-openai gem and create call extraction services</name>
  <files>
    api/Gemfile
    api/app/services/calls/extraction_service.rb
    api/app/services/calls/prompt_builder.rb
    api/app/services/calls/call_parser.rb
  </files>
  <action>
    1. Add `ruby-openai` gem to Gemfile: `gem "ruby-openai", "~> 8.3"` and run `bundle install`.

    2. Create `api/app/services/calls/prompt_builder.rb`:
       - Class `Calls::PromptBuilder` with class methods `system_prompt` and `user_prompt(content)`
       - `system_prompt` returns the detailed system prompt from 03-RESEARCH.md (the CALL_EXTRACTION_SYSTEM_PROMPT). Include:
         - Definition of what a "call" is (explicit, actionable, current)
         - Negative examples (reporting, past actions, hypotheticals, negations)
         - Supported asset list: BTC, ETH, SOL, XRP, ADA, DOT, AVAX, LINK, MATIC, DOGE, SHIB, NASDAQ, SP500, DXY, GOLD
         - JSON output format specification with asset, direction, confidence, quote, reasoning
         - Rules: confidence 0-1, direction bullish/bearish, asset from supported list only, quote max 200 chars, only include >= 0.5 confidence
       - `user_prompt(content)` builds user message:
         - For YoutubeVideo: "Analyze this YouTube video transcript for market calls:\n\nTitle: #{content.title}\n\n#{content.transcript}"
         - For Tweet: "Analyze this tweet for market calls:\n\n#{content.body}"
         - Truncate text to 50,000 characters max to control token costs

    3. Create `api/app/services/calls/call_parser.rb`:
       - Class `Calls::CallParser` with class method `parse(json_string, content)`
       - Parse JSON string, extract "calls" array
       - For each call in the array:
         - Find asset by symbol using `Asset.find_by(symbol: call_data["asset"])`
         - Skip if asset not found (unknown asset not in our list)
         - Skip if confidence < 0.5 (should be filtered by LLM but double-check)
         - Build a Call record with:
           - content: content
           - influencer: content.influencer
           - asset: found asset
           - direction: call_data["direction"]
           - confidence: call_data["confidence"]
           - quote: call_data["quote"]
           - reasoning: call_data["reasoning"]
           - called_at: content.published_at || content.created_at
       - Return array of built (unsaved) Call records
       - Rescue JSON::ParserError and return empty array with Rails.logger.error

    4. Create `api/app/services/calls/extraction_service.rb`:
       - Class `Calls::ExtractionService` with instance method `extract(content)`
       - Initialize OpenAI client: `OpenAI::Client.new(access_token: ENV["OPENAI_API_KEY"])`
       - Skip if content.extraction_status == "completed" (already processed)
       - Skip if content is YoutubeVideo and transcript is blank -- set extraction_status to "no_transcript" and return
       - Skip if content is Tweet and body is blank -- set extraction_status to "no_content" and return
       - Build prompts using PromptBuilder
       - Call OpenAI chat API with:
         - model: "gpt-4o-mini"
         - response_format: { type: "json_object" }
         - temperature: 0.1
         - max_tokens: 1000
         - messages: [system_prompt, user_prompt]
       - Extract JSON from response: `response.dig("choices", 0, "message", "content")`
       - Parse with CallParser
       - Filter: only save calls with confidence >= 0.7
       - Save valid calls in a transaction
       - Update content: calls_extracted_at = Time.current, extraction_status = "completed" (or "no_calls" if no calls found, "low_confidence" if all calls were below 0.7)
       - Log token usage from response["usage"]["total_tokens"]
       - Rescue OpenAI errors (Faraday::Error, etc.) -- set extraction_status to "failed", log error, re-raise for job retry
  </action>
  <verify>
    Run `bundle install` successfully.
    Run `ruby -c api/app/services/calls/prompt_builder.rb` -- syntax OK.
    Run `ruby -c api/app/services/calls/call_parser.rb` -- syntax OK.
    Run `ruby -c api/app/services/calls/extraction_service.rb` -- syntax OK.
    Run `bin/rails runner "puts Calls::PromptBuilder.system_prompt.length > 500"` -- should print true.
  </verify>
  <done>ruby-openai gem installed. Three service classes created: PromptBuilder (system/user prompts with supported asset list and negative examples), CallParser (JSON to Call records with asset lookup), ExtractionService (orchestrates LLM call, parsing, and status updates).</done>
</task>

<task type="auto">
  <name>Task 2: Create extraction background jobs and recurring schedule</name>
  <files>
    api/app/jobs/extract_calls_job.rb
    api/app/jobs/extract_all_pending_calls_job.rb
    api/config/recurring.yml
  </files>
  <action>
    1. Create `api/app/jobs/extract_calls_job.rb`:
       - Class ExtractCallsJob < ApplicationJob
       - queue_as :extraction
       - retry_on Faraday::Error, wait: :polynomially_longer, attempts: 3
       - discard_on ActiveRecord::RecordNotFound
       - `perform(content_id)`:
         - Find content by ID
         - Call `Calls::ExtractionService.new.extract(content)`
         - Log completion: "Extracted calls for Content ##{content_id}"

    2. Create `api/app/jobs/extract_all_pending_calls_job.rb`:
       - Class ExtractAllPendingCallsJob < ApplicationJob
       - queue_as :extraction
       - `perform`:
         - Find all content where extraction_status is "pending" or nil
         - For YoutubeVideo: also require transcript to be present (not nil/blank)
         - For Tweet: require body to be present
         - Use `.find_each` for memory efficiency
         - Enqueue `ExtractCallsJob.perform_later(content.id)` for each
         - Log: "Enqueued extraction for #{count} content items"

    3. Update `api/config/recurring.yml`:
       - Add to production section:
         ```
         extract_all_pending_calls:
           class: ExtractAllPendingCallsJob
           schedule: every hour at minute 15
           queue: extraction
         ```
       - Add to development section:
         ```
         extract_all_pending_calls:
           class: ExtractAllPendingCallsJob
           schedule: every 10 minutes
         ```
       - This staggers extraction at :15, after YouTube (:00) and Twitter (:30) have time to ingest new content. Content ingested at :00 and :30 will be extracted starting at :15 of the next hour.
  </action>
  <verify>
    Run `ruby -c api/app/jobs/extract_calls_job.rb` -- syntax OK.
    Run `ruby -c api/app/jobs/extract_all_pending_calls_job.rb` -- syntax OK.
    Run `bin/rails runner "puts ExtractCallsJob.queue_name"` -- should print "extraction".
    Run `bin/rails runner "puts ExtractAllPendingCallsJob.queue_name"` -- should print "extraction".
    Verify recurring.yml has extract_all_pending_calls in both production and development sections.
  </verify>
  <done>Two background jobs created: ExtractCallsJob (per-content with retry on API errors), ExtractAllPendingCallsJob (batch dispatcher finding unprocessed content). Recurring schedule updated with extraction at :15 past the hour.</done>
</task>

</tasks>

<verification>
- `bundle exec ruby -e "require 'openai'; puts OpenAI::VERSION"` prints a version
- All service files pass syntax check
- All job files pass syntax check
- recurring.yml is valid YAML with extraction jobs in both environments
- Service classes are loadable: `bin/rails runner "puts Calls::ExtractionService.new.class"`
</verification>

<success_criteria>
- ruby-openai gem installed and loadable
- ExtractionService sends content to GPT-4o-mini with JSON mode and structured prompt
- PromptBuilder includes supported asset list, negative examples, and JSON format specification
- CallParser creates Call records with asset lookup, filtering unknown assets
- Only calls with confidence >= 0.7 are persisted; others set status appropriately
- Content extraction_status updated after processing (completed/no_calls/no_transcript/failed/low_confidence)
- Batch job finds pending content and dispatches per-content extraction jobs
- Recurring schedule runs extraction at :15 past the hour (after ingestion completes)
</success_criteria>

<output>
After completion, create `.planning/phases/03-call-extraction-price-data/03-02-SUMMARY.md`
</output>
